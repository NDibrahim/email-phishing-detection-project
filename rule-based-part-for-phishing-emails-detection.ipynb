{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6886729,"sourceType":"datasetVersion","datasetId":3956180}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================\n# Imports & Regex definitions\n# ============================\n\nimport re\nfrom urllib.parse import urlparse\nfrom collections import Counter\n\nimport numpy as np\nimport pandas as pd\n\n# Optional libs\ntry:\n    from bs4 import BeautifulSoup\nexcept Exception:\n    BeautifulSoup = None\n\ntry:\n    import tldextract\nexcept Exception:\n    tldextract = None\n\n# Email parsing\nfrom email import policy\nfrom email.parser import BytesParser, Parser\n\n# sklearn (only used for quick baseline)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import StratifiedKFold, cross_validate\n\n# Regexes\nURL_RE = re.compile(r'https?://[^\\s\\'\">)]+', re.IGNORECASE)\nIP_URL_RE = re.compile(r'https?://(?:\\d{1,3}\\.){3}\\d{1,3}(?:[:/]|$)')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:07:48.196451Z","iopub.execute_input":"2025-12-04T19:07:48.196929Z","iopub.status.idle":"2025-12-04T19:07:49.384412Z","shell.execute_reply.started":"2025-12-04T19:07:48.196898Z","shell.execute_reply":"2025-12-04T19:07:49.383670Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ======================================\n# Parse raw RFC-822 email into components\n# ======================================\n\ndef parse_raw_email(raw):\n    \"\"\"\n    Parse raw RFC-822 email (str or bytes) and return dict:\n    { 'headers', 'subject', 'plain', 'html', 'attachments' }\n    \"\"\"\n    if raw is None:\n        return None\n\n    if isinstance(raw, bytes):\n        msg = BytesParser(policy=policy.default).parsebytes(raw)\n    else:\n        msg = Parser(policy=policy.default).parsestr(raw)\n\n    headers = dict(msg.items())\n    subject = msg.get(\"Subject\", \"\") or \"\"\n\n    plain_parts, html_parts, attachments = [], [], []\n\n    if msg.is_multipart():\n        for part in msg.walk():\n            ctype = part.get_content_type()\n            disp = part.get_content_disposition()\n\n            # Attachments\n            if disp == \"attachment\" or part.get_filename():\n                try:\n                    payload_bytes = part.get_payload(decode=True) or b\"\"\n                    size = len(payload_bytes)\n                except Exception:\n                    size = 0\n\n                attachments.append({\n                    \"filename\": part.get_filename(),\n                    \"content_type\": ctype,\n                    \"size\": size\n                })\n                continue\n\n            # Body\n            try:\n                payload = part.get_content()\n            except Exception:\n                payload = None\n\n            if ctype == \"text/plain\" and payload:\n                plain_parts.append(str(payload))\n            elif ctype == \"text/html\" and payload:\n                html_parts.append(str(payload))\n    else:\n        ctype = msg.get_content_type()\n        try:\n            payload = msg.get_content()\n        except Exception:\n            payload = msg.get_payload(decode=True)\n            if isinstance(payload, bytes):\n                payload = payload.decode(errors=\"replace\")\n\n        if ctype == \"text/plain\":\n            plain_parts.append(payload or \"\")\n        elif ctype == \"text/html\":\n            html_parts.append(payload or \"\")\n\n    return {\n        \"headers\": headers,\n        \"subject\": subject,\n        \"plain\": \"\\n\".join([p for p in plain_parts if p]),\n        \"html\": \"\\n\".join([p for p in html_parts if p]),\n        \"attachments\": attachments\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:07:54.724387Z","iopub.execute_input":"2025-12-04T19:07:54.725017Z","iopub.status.idle":"2025-12-04T19:07:54.737256Z","shell.execute_reply.started":"2025-12-04T19:07:54.724984Z","shell.execute_reply":"2025-12-04T19:07:54.736278Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================\n# URL extraction and features\n# ============================\n\ndef extract_urls(text):\n    if not isinstance(text, str) or not text:\n        return []\n    return URL_RE.findall(text)\n\n\ndef url_features(urls):\n    feats = {}\n\n    feats[\"url_count\"] = len(urls)\n    feats[\"unique_domain_count\"] = len({urlparse(u).netloc for u in urls})\n    feats[\"has_ip_url\"] = int(any(IP_URL_RE.search(u) for u in urls))\n\n    feats[\"max_url_length\"] = max([len(u) for u in urls], default=0)\n    feats[\"mean_url_length\"] = float(np.mean([len(u) for u in urls])) if urls else 0.0\n\n    feats[\"has_punycode\"] = int(any(\"xn--\" in urlparse(u).netloc for u in urls))\n\n    suspicious_tokens = [\"login\", \"secure\", \"account\", \"update\", \"verify\", \"confirm\", \"bank\", \"ebay\", \"paypal\"]\n    feats[\"suspicious_token_in_url\"] = int(\n        sum(any(tok in u.lower() for tok in suspicious_tokens) for u in urls)\n    )\n\n    # Domain extraction\n    domains = []\n    for u in urls:\n        netloc = urlparse(u).netloc.lower()\n\n        if tldextract:\n            try:\n                ex = tldextract.extract(u)\n                domain = \".\".join([ex.domain, ex.suffix]) if ex.suffix else ex.domain\n            except Exception:\n                domain = netloc\n        else:\n            domain = netloc\n\n        domains.append(domain)\n\n    feats[\"most_common_domain_freq\"] = Counter(domains).most_common(1)[0][1] if domains else 0\n\n    return feats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:07:59.525889Z","iopub.execute_input":"2025-12-04T19:07:59.526198Z","iopub.status.idle":"2025-12-04T19:07:59.535441Z","shell.execute_reply.started":"2025-12-04T19:07:59.526176Z","shell.execute_reply":"2025-12-04T19:07:59.534543Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# ================================\n# HTML-based (if exists) features\n# ================================\n\ndef html_features(html):\n    feats = {}\n\n    if not isinstance(html, str) or html.strip() == \"\":\n        feats.update({\n            \"html_length\": 0,\n            \"html_script_tags\": 0,\n            \"html_iframe_tags\": 0,\n            \"html_hidden_inputs\": 0\n        })\n        return feats\n\n    feats[\"html_length\"] = len(html)\n\n    if BeautifulSoup:\n        soup = BeautifulSoup(html, \"html.parser\")\n        feats[\"html_script_tags\"] = len(soup.find_all(\"script\"))\n        feats[\"html_iframe_tags\"] = len(soup.find_all(\"iframe\"))\n        feats[\"html_hidden_inputs\"] = len(soup.find_all(\"input\", {\"type\": \"hidden\"}))\n    else:\n        feats[\"html_script_tags\"] = html.lower().count(\"<script\")\n        feats[\"html_iframe_tags\"] = html.lower().count(\"<iframe\")\n        feats[\"html_hidden_inputs\"] = html.lower().count('type=\"hidden\"')\n\n    return feats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:08:03.526829Z","iopub.execute_input":"2025-12-04T19:08:03.527172Z","iopub.status.idle":"2025-12-04T19:08:03.533919Z","shell.execute_reply.started":"2025-12-04T19:08:03.527147Z","shell.execute_reply":"2025-12-04T19:08:03.532977Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ======================\n# Header-based features\n# ======================\n\ndef header_features(headers):\n    feats = {}\n\n    # Normalize keys\n    headers = {str(k).lower(): (v if isinstance(v, str) else str(v)) for k, v in headers.items()}\n\n    # Safe get + convert to string\n    reply_to = str(headers.get(\"reply-to\", \"\") or \"\").lower()\n    from_h  = str(headers.get(\"from\", \"\") or \"\").lower()\n\n    # Safe boolean\n    if reply_to and from_h:\n        feats[\"reply_to_diff_from\"] = int(reply_to not in from_h)\n    else:\n        feats[\"reply_to_diff_from\"] = 0  # no info → not phishing by default\n\n    # SPF / DKIM / DMARC\n    auth_res = str(headers.get(\"authentication-results\", \"\") or \"\").lower()\n    feats[\"spf_pass\"] = int(\"spf=pass\" in auth_res)\n    feats[\"dkim_pass\"] = int(\"dkim=pass\" in auth_res)\n    feats[\"dmarc_pass\"] = int(\"dmarc=pass\" in auth_res)\n\n    # Subject\n    subject = str(headers.get(\"subject\", \"\") or \"\")\n    s = subject.lower()\n\n    feats[\"subject_len\"] = len(subject)\n    feats[\"subject_has_urgent\"] = int(\"urgent\" in s)\n    feats[\"subject_has_verify\"] = int(\"verify\" in s)\n    feats[\"subject_has_action\"] = int(\"action required\" in s)\n\n    return feats\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:12:28.793547Z","iopub.execute_input":"2025-12-04T19:12:28.793982Z","iopub.status.idle":"2025-12-04T19:12:28.802113Z","shell.execute_reply.started":"2025-12-04T19:12:28.793957Z","shell.execute_reply":"2025-12-04T19:12:28.801156Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ==============================\n# Combine everything\n# ==============================\n\ndef extract_all_features(raw_email):\n    parsed = parse_raw_email(raw_email)\n\n    urls = extract_urls(parsed[\"plain\"]) + extract_urls(parsed[\"html\"])\n\n    feats = {}\n    feats.update(url_features(urls))\n    feats.update(html_features(parsed[\"html\"]))\n    feats.update(header_features(parsed[\"headers\"]))\n\n    return feats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:08:10.780520Z","iopub.execute_input":"2025-12-04T19:08:10.781181Z","iopub.status.idle":"2025-12-04T19:08:10.788998Z","shell.execute_reply.started":"2025-12-04T19:08:10.781149Z","shell.execute_reply":"2025-12-04T19:08:10.787275Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# ==============================\n# Convert list of raw emails to\n# a dataframe of features\n# ==============================\n\ndef emails_to_feature_df(raw_emails):\n    rows = []\n    for raw in raw_emails:\n        feats = extract_all_features(raw)\n        rows.append(feats)\n    return pd.DataFrame(rows)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:08:17.442942Z","iopub.execute_input":"2025-12-04T19:08:17.443239Z","iopub.status.idle":"2025-12-04T19:08:17.447920Z","shell.execute_reply.started":"2025-12-04T19:08:17.443219Z","shell.execute_reply":"2025-12-04T19:08:17.446968Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# DIAG 1 — quick sanity checks on df_raw\nprint(\"df_raw shape:\", df_raw.shape)\nprint(\"first 10 rows (id, label, path):\")\ndisplay(df_raw.head(10)[[\"id\", \"label\", \"path\"]])\n\n# show path sizes and counts\nimport os\nsizes = []\nfor p in df_raw[\"path\"].tolist()[:30]:\n    try:\n        sizes.append((p, os.path.getsize(p)))\n    except Exception:\n        sizes.append((p, None))\nprint(\"sample path sizes (first 30):\")\nfor p,s in sizes[:30]:\n    print(p, \"->\", s)\n    \nprint(\"\\nLabel distribution:\")\nprint(df_raw['label'].value_counts(dropna=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:17:40.090167Z","iopub.execute_input":"2025-12-04T19:17:40.090593Z","iopub.status.idle":"2025-12-04T19:17:40.116723Z","shell.execute_reply.started":"2025-12-04T19:17:40.090558Z","shell.execute_reply":"2025-12-04T19:17:40.115944Z"}},"outputs":[{"name":"stdout","text":"df_raw shape: (1, 5)\nfirst 10 rows (id, label, path):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              id label                                               path\n0  trec05p-1.tgz  spam  /kaggle/input/emails-for-spam-or-ham-classific...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>trec05p-1.tgz</td>\n      <td>spam</td>\n      <td>/kaggle/input/emails-for-spam-or-ham-classific...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"sample path sizes (first 30):\n/kaggle/input/emails-for-spam-or-ham-classification-trec-2005/trec05p-1.tgz -> 317224633\n\nLabel distribution:\nlabel\nspam    1\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cell 1 — find CSVs and load them (auto-detect common names)\nfrom pathlib import Path\nimport pandas as pd\nimport json\n\nINPUT_ROOT = Path(\"/kaggle/input\")\ncand = [p for p in INPUT_ROOT.iterdir() if p.is_dir()]\n\n# try to find the folder that contains your unzipped dataset\ndataset_root = None\nfor p in cand:\n    name = p.name.lower()\n    if \"trec\" in name or \"emails\" in name or \"email\" in name or \"spam\" in name:\n        dataset_root = p\n        break\nif dataset_root is None:\n    dataset_root = cand[0] if cand else None\n\nif dataset_root is None:\n    raise RuntimeError(\"Could not find dataset folder under /kaggle/input. Please set dataset_root manually.\")\n\nprint(\"Using dataset_root:\", dataset_root)\n\n# List CSVs in that folder (non-recursive) and try to pick header/body CSVs\ncsvs = list(dataset_root.glob(\"*.csv\"))\nprint(\"Top-level CSV files:\", [c.name for c in csvs])\n\n# If many CSVs exist, search recursively (some datasets place CSVs in subfolders)\nif not csvs:\n    csvs = list(dataset_root.rglob(\"*.csv\"))\n    print(\"Recursive CSV files:\", [c.name for c in csvs])\n\n# heuristics to choose header and body csv\nhdr_candidates = [c for c in csvs if any(k in c.name.lower() for k in (\"header\",\"headers\",\"meta\"))]\nbody_candidates = [c for c in csvs if any(k in c.name.lower() for k in (\"body\",\"bodies\",\"text\",\"message\"))]\n\n# fallback: if no candidates, pick first two distinct CSVs\nif not hdr_candidates and len(csvs) >= 1:\n    hdr_candidates = [csvs[0]]\nif not body_candidates and len(csvs) >= 2:\n    body_candidates = [csvs[1]] if csvs[1] != hdr_candidates[0] else ([csvs[0]] if len(csvs)>0 else [])\n\nprint(\"Header candidate(s):\", [p.name for p in hdr_candidates])\nprint(\"Body candidate(s):\", [p.name for p in body_candidates])\n\nif not hdr_candidates or not body_candidates:\n    raise RuntimeError(\"Couldn't auto-detect header/body CSVs. Please check the dataset structure or set paths manually.\")\n\nhdr_path = hdr_candidates[0]\nbody_path = body_candidates[0]\n\nprint(\"Loading header CSV:\", hdr_path)\nprint(\"Loading body   CSV:\", body_path)\n\ndf_hdr = pd.read_csv(hdr_path, low_memory=False)\ndf_body = pd.read_csv(body_path, low_memory=False)\n\nprint(\"Header DF shape:\", df_hdr.shape)\nprint(\"Body   DF shape:\", df_body.shape)\n\ndisplay(df_hdr.head(3))\ndisplay(df_body.head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:24:14.575062Z","iopub.execute_input":"2025-12-04T19:24:14.575445Z","iopub.status.idle":"2025-12-04T19:24:27.418782Z","shell.execute_reply.started":"2025-12-04T19:24:14.575419Z","shell.execute_reply":"2025-12-04T19:24:27.417857Z"}},"outputs":[{"name":"stdout","text":"Using dataset_root: /kaggle/input/emails-for-spam-or-ham-classification-trec-2005\nTop-level CSV files: ['email_origin.csv', 'email_text.csv']\nHeader candidate(s): ['email_origin.csv']\nBody candidate(s): ['email_text.csv']\nLoading header CSV: /kaggle/input/emails-for-spam-or-ham-classification-trec-2005/email_origin.csv\nLoading body   CSV: /kaggle/input/emails-for-spam-or-ham-classification-trec-2005/email_text.csv\nHeader DF shape: (92189, 2)\nBody   DF shape: (55075, 2)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   label                                             origin\n0      0  Received: from NAHOU-MSMBX01V ([192.168.110.39...\n1      0  Received: from nahou-msmbx03v.corp.enron.com (...\n2      0  Received: from NAHOU-MSMBX01V ([192.168.110.39...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Received: from NAHOU-MSMBX01V ([192.168.110.39...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Received: from nahou-msmbx03v.corp.enron.com (...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Received: from NAHOU-MSMBX01V ([192.168.110.39...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"   label                                               text\n0      0  user id enrondlr pw bnawebescapenumber origina...\n1      0  hi chris tonight we are rolling out a new repo...\n2      0  rika r these new original message from thomas ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>user id enrondlr pw bnawebescapenumber origina...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>hi chris tonight we are rolling out a new repo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>rika r these new original message from thomas ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Cell 2 — detect ID columns and text columns, normalize formats\nfrom ast import literal_eval\n\ndef find_id_col(df):\n    # common id names\n    for c in (\"id\",\"msg_id\",\"message_id\",\"mail_id\",\"filename\",\"file\"):\n        if c in df.columns:\n            return c\n    # fallback: index as id\n    return None\n\ndef find_text_col_for_body(df):\n    for c in (\"body\",\"raw\",\"raw_body\",\"message\",\"text\",\"plain\",\"content\",\"email\"):\n        if c in df.columns:\n            return c\n    # fallback: first object column\n    for c in df.columns:\n        if df[c].dtype == object:\n            return c\n    return None\n\ndef find_headers_col(df):\n    for c in (\"headers\",\"raw_headers\",\"header\",\"all_headers\",\"metadata\"):\n        if c in df.columns:\n            return c\n    # fallback: any object column\n    for c in df.columns:\n        if df[c].dtype == object:\n            return c\n    return None\n\nid_hdr = find_id_col(df_hdr)\nid_body = find_id_col(df_body)\nbody_col = find_text_col_for_body(df_body)\nhdr_col = find_headers_col(df_hdr)\n\nprint(\"Detected header id col:\", id_hdr)\nprint(\"Detected body id col:  \", id_body)\nprint(\"Detected body text col:\", body_col)\nprint(\"Detected header col:   \", hdr_col)\n\n# If no id columns, create synthetic ids by index\nif id_hdr is None:\n    df_hdr = df_hdr.reset_index().rename(columns={\"index\":\"id_hdr\"})\n    id_hdr = \"id_hdr\"\nif id_body is None:\n    df_body = df_body.reset_index().rename(columns={\"index\":\"id_body\"})\n    id_body = \"id_body\"\n\n# If ids exist but names differ, try to rename to \"id\" for merge simplicity\nif id_hdr != \"id\":\n    df_hdr = df_hdr.rename(columns={id_hdr:\"id\"})\n    id_hdr = \"id\"\nif id_body != \"id\":\n    df_body = df_body.rename(columns={id_body:\"id\"})\n    id_body = \"id\"\n\n# If the header column appears to be JSON strings, parse them\ndef safe_parse_headers_cell(x):\n    if pd.isna(x):\n        return {}\n    if isinstance(x, dict):\n        return x\n    if isinstance(x, str):\n        s = x.strip()\n        # try json\n        try:\n            return json.loads(s)\n        except Exception:\n            pass\n        # try literal_eval (python dict-like)\n        try:\n            return literal_eval(s)\n        except Exception:\n            pass\n        # otherwise, return the raw string under a special key\n        return {\"raw_headers_text\": s}\n    # other types -> string\n    return {\"raw_headers_text\": str(x)}\n\n# Apply parsing if we found a hdr_col\nif hdr_col is not None and hdr_col in df_hdr.columns:\n    # create a normalized headers_dict column\n    df_hdr[\"_headers_dict\"] = df_hdr[hdr_col].apply(safe_parse_headers_cell)\nelse:\n    df_hdr[\"_headers_dict\"] = [{} for _ in range(len(df_hdr))]\n\n# Show a sample header dict\ndisplay(df_hdr[[\"_headers_dict\"]].head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:24:46.904342Z","iopub.execute_input":"2025-12-04T19:24:46.905233Z","iopub.status.idle":"2025-12-04T19:24:50.015351Z","shell.execute_reply.started":"2025-12-04T19:24:46.905200Z","shell.execute_reply":"2025-12-04T19:24:50.014575Z"}},"outputs":[{"name":"stdout","text":"Detected header id col: None\nDetected body id col:   None\nDetected body text col: text\nDetected header col:    origin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                       _headers_dict\n0  {'raw_headers_text': 'Received: from NAHOU-MSM...\n1  {'raw_headers_text': 'Received: from nahou-msm...\n2  {'raw_headers_text': 'Received: from NAHOU-MSM...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_headers_dict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'raw_headers_text': 'Received: from NAHOU-MSM...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'raw_headers_text': 'Received: from nahou-msm...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'raw_headers_text': 'Received: from NAHOU-MSM...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Cell 3 — merge on 'id' and create a synthetic raw_str if needed\nimport numpy as np\n\n# Merge\ndf = pd.merge(df_hdr, df_body, on=\"id\", how=\"outer\", suffixes=(\"_hdr\",\"_body\"))\nprint(\"Merged df shape:\", df.shape)\ndisplay(df.head(3))\n\n# Determine actual body column name after merge (body_col may have been renamed)\npossible_body_cols = [c for c in df.columns if any(k in c.lower() for k in (\"body\",\"plain\",\"text\",\"raw\",\"message\",\"content\"))]\n# prefer exact body_col if detected earlier\nif body_col and body_col in df.columns:\n    body_col_name = body_col\nelse:\n    # pick the best candidate\n    body_col_name = possible_body_cols[0] if possible_body_cols else None\n\nprint(\"Using body column:\", body_col_name)\n\n# Build raw_str: if we have headers dict, convert to header block; else use headers text if available.\ndef headers_dict_to_block(h):\n    if not h:\n        return \"\"\n    # if it's already a dict of header->value\n    if isinstance(h, dict):\n        lines = []\n        for k,v in h.items():\n            lines.append(f\"{k}: {v}\")\n        return \"\\n\".join(lines)\n    # fallback\n    return str(h)\n\ndef make_raw_str(row):\n    hdr_dict = row.get(\"_headers_dict\", {}) or {}\n    hdr_block = headers_dict_to_block(hdr_dict)\n    # if there is a raw headers string column (some CSVs keep a text column), prefer it\n    fallback_hdr_texts = [c for c in df.columns if c.lower() in (\"raw_headers\",\"headers\",\"raw\",\"header\",\"all_headers\",\"metadata\")]\n    hdr_text = \"\"\n    for c in fallback_hdr_texts:\n        if c in row and pd.notna(row[c]):\n            hdr_text = str(row[c])\n            break\n    # choose the most informative header part\n    header_section = hdr_text if hdr_text else hdr_block\n\n    body = \"\"\n    if body_col_name and pd.notna(row.get(body_col_name, \"\")):\n        body = str(row.get(body_col_name, \"\"))\n    # combine\n    combined = f\"{header_section}\\n\\n{body}\"\n    return combined\n\ndf[\"raw_str\"] = df.apply(make_raw_str, axis=1)\n\n# sanity check counts\nprint(\"Rows after merge:\", len(df))\nprint(\"Sample id/path/label/raw_str preview:\")\ndisplay(df[[\"id\"]].head(3))\nprint(df[\"raw_str\"].iloc[0][:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:25:20.802948Z","iopub.execute_input":"2025-12-04T19:25:20.803592Z","iopub.status.idle":"2025-12-04T19:25:23.364350Z","shell.execute_reply.started":"2025-12-04T19:25:20.803547Z","shell.execute_reply":"2025-12-04T19:25:23.363626Z"}},"outputs":[{"name":"stdout","text":"Merged df shape: (92189, 6)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   id  label_hdr                                             origin  \\\n0   0          0  Received: from NAHOU-MSMBX01V ([192.168.110.39...   \n1   1          0  Received: from nahou-msmbx03v.corp.enron.com (...   \n2   2          0  Received: from NAHOU-MSMBX01V ([192.168.110.39...   \n\n                                       _headers_dict  label_body  \\\n0  {'raw_headers_text': 'Received: from NAHOU-MSM...         0.0   \n1  {'raw_headers_text': 'Received: from nahou-msm...         0.0   \n2  {'raw_headers_text': 'Received: from NAHOU-MSM...         0.0   \n\n                                                text  \n0  user id enrondlr pw bnawebescapenumber origina...  \n1  hi chris tonight we are rolling out a new repo...  \n2  rika r these new original message from thomas ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label_hdr</th>\n      <th>origin</th>\n      <th>_headers_dict</th>\n      <th>label_body</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Received: from NAHOU-MSMBX01V ([192.168.110.39...</td>\n      <td>{'raw_headers_text': 'Received: from NAHOU-MSM...</td>\n      <td>0.0</td>\n      <td>user id enrondlr pw bnawebescapenumber origina...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>Received: from nahou-msmbx03v.corp.enron.com (...</td>\n      <td>{'raw_headers_text': 'Received: from nahou-msm...</td>\n      <td>0.0</td>\n      <td>hi chris tonight we are rolling out a new repo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>Received: from NAHOU-MSMBX01V ([192.168.110.39...</td>\n      <td>{'raw_headers_text': 'Received: from NAHOU-MSM...</td>\n      <td>0.0</td>\n      <td>rika r these new original message from thomas ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Using body column: text\nRows after merge: 92189\nSample id/path/label/raw_str preview:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   id\n0   0\n1   1\n2   2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"raw_headers_text: Received: from NAHOU-MSMBX01V ([192.168.110.39]) by NAHOU-MSMBX05V.corp.enron.com with Microsoft SMTPSVC(5.0.2195.1600);\n\t Fri, 29 Jun 2001 08:36:10 -0500\nX-MimeOLE: Produced By Microsoft Exchange V6.0.4418.65\ncontent-class: urn:content-classes:message\nSubject: FW: June 29 -- BNA, Inc. Daily Labor Report\nMIME-Version: 1.0\nContent-Type: text/plain;\nContent-Transfer-Encoding: binary\nDate: Fri, 29 Jun 2001 08:36:09 -0500\nMessage-ID: <77DA52C3FD86904D8209C9750CD310B9C79BB3@NAHOU-MS\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Cell 4 — apply extract_all_features (robustly) and save features to CSV\nimport csv\nfrom tqdm.notebook import tqdm\n\nOUT = \"/kaggle/working/trec_features_from_csvs.csv\"\n\n# build union of feature keys from a small sample (to create header)\nsample_n = min(200, len(df))\nall_keys = set()\nfor i in range(sample_n):\n    raw = df.loc[i, \"raw_str\"]\n    try:\n        feats = extract_all_features(raw)\n        if isinstance(feats, dict):\n            all_keys.update(feats.keys())\n    except Exception:\n        # fallback partial extraction using parse_raw_email + helpers\n        try:\n            parsed = parse_raw_email(raw)\n            tmp = {}\n            tmp.update(url_features(extract_urls(parsed.get(\"plain\",\"\") or \"\")))\n            tmp.update(html_features(parsed.get(\"html\",\"\") or \"\"))\n            tmp.update(header_features(parsed.get(\"headers\", {}) or {}))\n            all_keys.update(tmp.keys())\n        except Exception:\n            pass\n\nfeat_cols = sorted(list(all_keys))\nbase_cols = [\"id\"]\nheader = base_cols + feat_cols + [\"label\"]\nprint(\"Feature columns detected:\", len(feat_cols))\n\n# write header\nwith open(OUT, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n    writer = csv.DictWriter(f, fieldnames=header)\n    writer.writeheader()\n\n# extract for all rows\nfor idx in tqdm(range(len(df)), desc=\"extract_all\"):\n    rid = df.loc[idx, \"id\"]\n    lbl = df.loc[idx].get(\"label\", \"\")\n    raw = df.loc[idx, \"raw_str\"]\n    try:\n        feats = extract_all_features(raw)\n        if not isinstance(feats, dict):\n            feats = {}\n    except Exception as e:\n        try:\n            parsed = parse_raw_email(raw)\n            feats = {}\n            feats.update(url_features(extract_urls(parsed.get(\"plain\",\"\") or \"\")))\n            feats.update(html_features(parsed.get(\"html\",\"\") or \"\"))\n            feats.update(header_features(parsed.get(\"headers\", {}) or {}))\n        except Exception as e2:\n            feats = {\"error_extract\": str(e)}\n    rowd = {\"id\": rid, \"label\": lbl}\n    for c in feat_cols:\n        rowd[c] = feats.get(c, 0)\n    # append row\n    with open(OUT, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n        writer = csv.DictWriter(f, fieldnames=header)\n        writer.writerow(rowd)\n\nprint(\"Saved features to:\", OUT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:26:33.763071Z","iopub.execute_input":"2025-12-04T19:26:33.763761Z","iopub.status.idle":"2025-12-04T19:35:23.435190Z","shell.execute_reply.started":"2025-12-04T19:26:33.763730Z","shell.execute_reply":"2025-12-04T19:35:23.434165Z"}},"outputs":[{"name":"stdout","text":"Feature columns detected: 20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"extract_all:   0%|          | 0/92189 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6014ea0a8dfd4a5696a1e47545803657"}},"metadata":{}},{"name":"stdout","text":"Saved features to: /kaggle/working/trec_features_from_csvs.csv\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Cell 5 — load the resulting features and check\nimport pandas as pd\ndf_feats = pd.read_csv(\"/kaggle/working/trec_features_from_csvs.csv\")\nprint(\"Features shape:\", df_feats.shape)\ndisplay(df_feats)\nprint(\"Label distribution:\")\nprint(df_feats['label'].value_counts(dropna=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T19:53:53.119441Z","iopub.execute_input":"2025-12-04T19:53:53.119902Z","iopub.status.idle":"2025-12-04T19:53:53.295288Z","shell.execute_reply.started":"2025-12-04T19:53:53.119876Z","shell.execute_reply":"2025-12-04T19:53:53.294284Z"}},"outputs":[{"name":"stdout","text":"Features shape: (92189, 22)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"          id  dkim_pass  dmarc_pass  has_ip_url  has_punycode  \\\n0          0          0           0           0             0   \n1          1          0           0           0             0   \n2          2          0           0           0             0   \n3          3          0           0           0             0   \n4          4          0           0           0             0   \n...      ...        ...         ...         ...           ...   \n92184  92184          0           0           0             0   \n92185  92185          0           0           0             0   \n92186  92186          0           0           0             0   \n92187  92187          0           0           0             0   \n92188  92188          0           0           0             0   \n\n       html_hidden_inputs  html_iframe_tags  html_length  html_script_tags  \\\n0                       0                 0            0                 0   \n1                       0                 0            0                 0   \n2                       0                 0            0                 0   \n3                       0                 0            0                 0   \n4                       0                 0            0                 0   \n...                   ...               ...          ...               ...   \n92184                   0                 0        16667                 0   \n92185                   0                 0        16667                 0   \n92186                   0                 0        16667                 0   \n92187                   0                 0        16667                 0   \n92188                   0                 0        16667                 0   \n\n       max_url_length  ...  reply_to_diff_from  spf_pass  subject_has_action  \\\n0                  49  ...                   0         0                   0   \n1                   0  ...                   0         0                   0   \n2                  60  ...                   0         0                   0   \n3                   0  ...                   0         0                   0   \n4                   0  ...                   0         0                   0   \n...               ...  ...                 ...       ...                 ...   \n92184             107  ...                   0         0                   0   \n92185             107  ...                   0         0                   0   \n92186             107  ...                   0         0                   0   \n92187             107  ...                   0         0                   0   \n92188             107  ...                   0         0                   0   \n\n       subject_has_urgent  subject_has_verify  subject_len  \\\n0                       0                   0           43   \n1                       0                   0           18   \n2                       0                   0           17   \n3                       0                   0           36   \n4                       0                   0           19   \n...                   ...                 ...          ...   \n92184                   0                   0           32   \n92185                   0                   0           32   \n92186                   0                   0           32   \n92187                   0                   0           32   \n92188                   0                   0           32   \n\n       suspicious_token_in_url  unique_domain_count  url_count  label  \n0                            0                    3         41    NaN  \n1                            0                    0          0    NaN  \n2                            0                    1          3    NaN  \n3                            0                    0          0    NaN  \n4                            0                    0          0    NaN  \n...                        ...                  ...        ...    ...  \n92184                        0                    2         71    NaN  \n92185                        0                    2         71    NaN  \n92186                        0                    2         71    NaN  \n92187                        0                    2         71    NaN  \n92188                        0                    2         71    NaN  \n\n[92189 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dkim_pass</th>\n      <th>dmarc_pass</th>\n      <th>has_ip_url</th>\n      <th>has_punycode</th>\n      <th>html_hidden_inputs</th>\n      <th>html_iframe_tags</th>\n      <th>html_length</th>\n      <th>html_script_tags</th>\n      <th>max_url_length</th>\n      <th>...</th>\n      <th>reply_to_diff_from</th>\n      <th>spf_pass</th>\n      <th>subject_has_action</th>\n      <th>subject_has_urgent</th>\n      <th>subject_has_verify</th>\n      <th>subject_len</th>\n      <th>suspicious_token_in_url</th>\n      <th>unique_domain_count</th>\n      <th>url_count</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>49</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>3</td>\n      <td>41</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92184</th>\n      <td>92184</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16667</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>92185</th>\n      <td>92185</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16667</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>92186</th>\n      <td>92186</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16667</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>92187</th>\n      <td>92187</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16667</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>92188</th>\n      <td>92188</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16667</td>\n      <td>0</td>\n      <td>107</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>32</td>\n      <td>0</td>\n      <td>2</td>\n      <td>71</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>92189 rows × 22 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Label distribution:\nlabel\nNaN    92189\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":22}]}